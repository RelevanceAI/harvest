# Superpowers Framework Integration Plan

**Date**: 2026-01-16
**Branch**: feat/superpowers-integration
**Complexity**: High (architectural changes, new workflows, multiple files)

---

## Summary

Integrate obra/superpowers framework skills into Harvest to strengthen autonomous agent capabilities with:
- Interactive brainstorming for complex features (Session 1)
- Detailed task-based planning (2-5 min granularity with hierarchical breakdown)
- Smart verification loops (not dogmatic TDD)
- Systematic debugging with failure escalation
- Memory-based learning from execution patterns
- Structured completion workflows

**Key Principle**: Adopt superpowers concepts while adapting to Harvest's autonomous execution model (no human checkpoints during Session 2).

---

## Context & Gemini Feedback

### What We're Adopting

**From Superpowers**:
- Brainstorming skill (interactive design validation)
- Writing-plans format (executable 2-5 min tasks)
- Test-driven development mindset (with flexibility)
- Verification-before-completion (evidence gates)
- Systematic-debugging (root cause investigation)
- Finishing-a-development-branch (4 structured options)

### Critical Fixes from Gemini Review

**BLOCKER 1**: Brainstorming can't be fully interactive during autonomous Session 1
- **Fix**: Agent evaluates complexity → interactive brainstorming if complex → autonomous plan writing

**BLOCKER 2**: Executing-plans checkpoints can't require human review during Session 2
- **Fix**: "Checkpoints" = automated verification (tests pass), not human gates

**BLOCKER 3**: Strict TDD "delete code" conflicts with fail-forward retries
- **Fix**: Smart verification loops with pre-commit advisory, not code deletion

**SHOULD 1**: 2-5 min task granularity creates huge plan files
- **Fix**: Hierarchical planning (5-10 high-level tasks in PR, agent breaks down during execution)

**SHOULD 2**: Unclear failure escalation (fail-forward vs systematic-debugging vs panic)
- **Fix**: Codified decision tree based on error type

---

## New Autonomous Workflow

### Session 1: Research + Planning (Interactive Where Needed)

```
Task arrives via Slack: "@harvest implement feature X"
  ↓
Modal Session 1 spins up
  ↓
┌─────────────────────────────────────────────────┐
│ Complexity Evaluation                           │
│ - Check against heuristic (architectural,       │
│   multi-module, new feature, uncertain, etc.)   │
│ - Query memory for similar past tasks           │
└─────────────────────────────────────────────────┘
  ↓
SIMPLE?                           COMPLEX?
  ↓                                 ↓
Skip brainstorming          Interactive brainstorming
  ↓                                 ↓
  │                         User Q&A to refine design
  │                         Explore 2-3 approaches
  │                         Present trade-offs
  │                         Validate incrementally
  │                                 ↓
  └──────────────┬──────────────────┘
                 ↓
       Autonomous Plan Writing
       - Use writing-plans format
       - 5-10 high-level tasks (30-60 min each)
       - Include verification approach per task
       - Store in .claude/plans/[branch]/plan_YYYY-MM-DD_HHMM.md
                 ↓
       Optional: Gemini adversarial review
                 ↓
       Create [PLAN] PR for human approval
                 ↓
       Session 1 ends
```

**Human reviews plan PR → approves or requests changes**

### Session 2: Execution (Fully Autonomous)

```
Slack: "@harvest execute plan-123"
  ↓
Modal Session 2 spins up
  ↓
Load approved plan from .claude/plans/[branch]/
  ↓
For each high-level task:
  ├─ Agent dynamically breaks into 2-5 min subtasks
  ├─ For each subtask:
  │   ├─ If logic code: Write failing test → Implement → Verify GREEN
  │   ├─ If docs/config: Make changes → Verify (lint/syntax)
  │   └─ Commit with appropriate message
  ├─ Automated checkpoint: Run test suite
  │   └─ If fails → Fail forward (3 attempts) → Systematic debugging → Panic if stuck
  └─ Continue to next task
  ↓
All tasks complete + tests pass
  ↓
Finishing-a-development-branch:
  ├─ Pre-check: Verify tests pass (BLOCKS if failing)
  ├─ Present 4 options: merge local / PR / keep / discard
  ├─ Execute chosen option
  └─ Auto-cleanup checkpoints on success
  ↓
Update memory with execution patterns
  ↓
Report to Slack (success with PR link, or panic report)
  ↓
Session 2 ends
```

---

## File Changes

### New Files to Create

1. **`docs/ai/shared/complexity-heuristic.md`**
   - Decision criteria for when to invoke brainstorming
   - Agent evaluates task against checklist
   - Memory query for similar past tasks

2. **`docs/ai/shared/verification.md`**
   - Smart verification loops (not dogmatic TDD)
   - When tests are required vs not required
   - Verification approaches per file type
   - Pre-commit advisory hook logic

3. **`docs/ai/shared/debugging.md`**
   - Failure escalation hierarchy
   - When to use fail-forward vs systematic-debugging
   - Panic button criteria
   - Recovery procedures

4. **`docs/ai/shared/finishing-workflow.md`**
   - 4-option completion framework
   - Test verification gate (blocks if failing)
   - Checkpoint cleanup timing
   - Memory updates after completion

5. **`.claude/plans/README.md` updates**
   - Add hierarchical planning section
   - Document 5-10 high-level tasks in plan PR
   - Agent breaks down during execution

6. **`config/memory-seed.json` updates**
   - Add ComplexityDecisions entity
   - Add VerificationPatterns entity
   - Add SuccessfulWorkflows entity
   - Add FailurePatterns entity

### Files to Update

1. **`docs/ai/autonomous-agent.md`**
   - Document two-session workflow
   - Reference complexity heuristic
   - Reference verification and debugging rules
   - Memory update requirements

2. **`docs/ai/local-development.md`**
   - Add brainstorming skill invocation guidance
   - Reference same complexity heuristic
   - Document when to use superpowers skills

3. **`.claude/CLAUDE.md`**
   - Reference superpowers skills availability
   - Link to complexity-heuristic for decision making
   - Clarify two-session autonomous workflow

4. **`docs/ai/shared/planning.md`**
   - Add hierarchical planning approach
   - Reference writing-plans format
   - 5-10 high-level tasks, dynamic breakdown during execution

---

## Detailed Implementation

### 1. Complexity Heuristic

**File**: `docs/ai/shared/complexity-heuristic.md`

```markdown
# Complexity Decision Heuristic

## When to Use Brainstorming

Before starting any task, evaluate against these criteria:

### Invoke `/superpowers:brainstorming` if ANY:

- ✅ **Architectural changes**: New modules, design patterns, infrastructure
- ✅ **Multi-module impact**: Changes span 3+ files across different subsystems
- ✅ **New feature**: Not a bug fix, refactor, or docs update
- ✅ **Uncertain approach**: Multiple valid solutions, unclear best path
- ✅ **User signals design**: Mentions "design", "architecture", "how should we"
- ✅ **High-risk areas**: Security, performance, data handling, payments, auth
- ✅ **Memory suggests**: Query memory for similar tasks that needed brainstorming

### Skip Brainstorming if ALL:

- ❌ Bug fix in single file with clear root cause
- ❌ Documentation/README/config changes only
- ❌ Simple refactor (rename, extract function, format)
- ❌ Clear, unambiguous task with obvious implementation
- ❌ Similar successful tasks skipped brainstorming (per memory)

### When Uncertain

Ask user directly:
"This task seems [simple/moderately complex]. Should I brainstorm the design approach, or proceed directly to planning?"

### Memory Integration

Before deciding:
```
memory_query("Similar tasks to [current task description]")
→ Check ComplexityDecisions entity
→ Did similar tasks need brainstorming?
→ What were outcomes?
```

After task completes:
```
memory_add_observation(
  entity="ComplexityDecisions",
  observation="[DATE] Task '[description]' → [brainstormed/skipped] → Plan [approved first try/needed revisions/rejected] → ASSESS: [GOOD CALL/SHOULD HAVE BRAINSTORMED/OVER-ENGINEERED]"
)
```
```

---

### 2. Smart Verification (Not Strict TDD)

**File**: `docs/ai/shared/verification.md`

```markdown
# Verification Guidelines

## Core Principle

**Evidence before claims.** Cannot assert "complete", "fixed", or "passing" without fresh verification.

## Test Requirements (Context-Aware)

### Tests REQUIRED for:

- ✅ New functions/methods/classes with logic
- ✅ Bug fixes (regression test to prevent recurrence)
- ✅ API endpoints or integration points
- ✅ Business logic, algorithms, data transformations
- ✅ State management or complex control flow
- ✅ Security-sensitive code (auth, validation, sanitization)

### Tests NOT Required for:

- ❌ Documentation (*.md, comments, JSDoc/TSDoc)
- ❌ Configuration files (package.json, tsconfig.json, .env)
- ❌ Pure type definitions (*.d.ts, interfaces without logic)
- ❌ Pure refactoring where existing tests cover behavior
- ❌ Formatting/linting-only changes
- ❌ Build scripts or tooling configuration

## Verification Approaches

### For Logic Code (Tests Required)

1. **Write failing test first** (watch it fail for right reason - RED)
2. **Implement minimum code** to pass the test
3. **Verify test passes** (GREEN)
4. **Run full test suite** (ensure no regressions)
5. **Commit both test + implementation together**

### For Non-Logic Changes (Tests Not Required)

1. **Make changes**
2. **Run existing test suite** (ensure no regressions)
3. **Additional verification**:
   - Docs: Lint check, manual review
   - Config: Validate syntax (JSON.parse, YAML lint)
   - Types: Run type-checker (`tsc --noEmit`)
   - Build: Run build command
4. **Commit changes**

## Pre-Commit Advisory

### Advisory Warning (Non-Blocking)

For most code changes with logic but no new tests:
```
⚠️  WARNING: These files have logic changes but no new tests:
  - src/classifier.ts
  - src/api/sessions.ts

✅ Proceeding with warning (use --no-verify to suppress)
```

### Blocking Enforcement (High-Risk Only)

For high-risk paths without tests:
```
❌ BLOCKED: High-risk changes require tests:
  - src/auth/authenticate.ts (authentication)
  - src/api/payments.ts (payment processing)

Add tests or use --no-verify to bypass (not recommended)
```

**High-risk patterns**:
- `auth`, `authenticate`, `login`, `session`
- `payment`, `billing`, `charge`, `transaction`
- `security`, `encrypt`, `decrypt`, `sanitize`
- `database`, `migration`, `schema`
- `api/**/*.ts` (API endpoints)

### Exemption Patterns

Never warn/block:
- `*.md` (Markdown)
- `README*`
- `*.json`, `*.yaml`, `*.yml` (Config)
- `*.d.ts` (Type definitions)
- `docs/**/*`
- `.github/**/*`

## 5-Step Verification Gate

Before any completion claim:

1. **Identify** the verification command that proves your claim
2. **Run** it freshly in current session (not from memory)
3. **Read** complete output including exit codes and failure counts
4. **Verify** output actually supports your claim
5. **Only then** state completion with evidence

### Examples

❌ **Bad** (no evidence):
```
"I've fixed the issue, tests should pass now"
"The implementation is complete"
```

✅ **Good** (evidence-based):
```
"Tests passing (ran `npm test`, all 47 tests green, exit 0)"
"Implementation complete, verified with:
  - npm test: 12/12 passing ✅
  - npm run type-check: no errors ✅
  - npm run build: success ✅"
```

## Memory Integration

After verification success/failure:
```
memory_add_observation(
  entity="VerificationPatterns",
  observation="[file type/path pattern] changes → [verification approach] → [worked/revealed issues]"
)
```

Examples:
- "src/api/*.ts changes → Integration tests required, unit tests insufficient → Caught auth bug"
- "Config changes (package.json) → Build + type-check sufficient, no tests needed → Worked"
```

---

### 3. Debugging & Failure Escalation

**File**: `docs/ai/shared/debugging.md`

```markdown
# Systematic Debugging & Failure Escalation

## Decision Tree

```
Error occurs
  ↓
Classify error type
  ↓
┌──────────────────┬──────────────────┬──────────────────┐
│ SIMPLE           │ COMPLEX          │ SYSTEM           │
│ (lint, syntax,   │ (logic bugs,     │ (permissions,    │
│  obvious)        │  integration)    │  disk, network)  │
└──────────────────┴──────────────────┴──────────────────┘
         ↓                  ↓                  ↓
   Fail Forward      Systematic          Panic Button
   (max 3 retries)   Debugging           (immediate)
         ↓                  ↓                  ↓
   Still failing?    3 fixes failed?
         ↓                  ↓
   → Systematic      → Panic Button
     Debugging
```

## Loop Detection (Circuit Breaker)

**Problem**: Agent can get stuck retrying same failed approach repeatedly.

**Solution**: Simple state-aware detection (start basic, iterate based on learnings).

**Gemini Validation**: RECOMMENDED approach - pragmatic starting point with viable iteration path.

### Simple Loop Detection (v1)

Before each debugging attempt:

```bash
# 1. Check if code changed since last attempt
CHANGED_FILES=$(git diff --name-only HEAD | wc -l)

# 2. Record attempt
memory_add_observation(
  entity="SessionProgress",
  observation="Attempt ${N}: ${action} (files changed: ${CHANGED_FILES}) → ${result}"
)

# 3. Check for loop (last 3 attempts)
recent_attempts = memory_query("SessionProgress last 3 attempts")

if (CHANGED_FILES == 0 && action == recent[-1].action) {
  # LOOP DETECTED: No code changes, trying same thing
  trigger_circuit_breaker()
}
```

### Circuit Breaker Actions

When loop detected:
1. **STOP** - Don't retry immediately
2. **Ask user**: "I've tried this approach 2-3x without code changes. Do you have a suggestion for a different direction?"
3. **OR** Enter plan mode for structured reset
4. **Clear** SessionProgress after human input (fresh start)

### What This Catches ✅

Obvious loops:
```
Attempt 1: npm test → FAIL (syntax error)
Attempt 2: npm test (no code changes) → FAIL (same error)
Attempt 3: npm test (no code changes) → LOOP DETECTED ✋
```

### Known Limitations (v1) ⚠️

Will NOT detect:

❌ **Environment changes** (HIGHEST PRIORITY if this fails):
```
rm -rf node_modules && npm install
git diff: 0 files (node_modules gitignored)
→ False positive: blocks retry
```

❌ **Same-file different-line changes**:
```
Fix line 45 → still fails
Fix line 46 (same file) → git diff shows change ✓
(Actually works correctly - git diff detects change)
```

❌ **Semantic loops** (fixing symptoms not root cause):
```
Agent makes code changes each time
But error remains the same
→ False negative: doesn't catch loop
```

❌ **Longer loops** (>3 steps):
```
Agent loops through 6-step cycle
Only checking last 3 attempts
→ Misses loop
```

### Mitigation Strategy

**Primary**: Panic Button backstop (3 retries → escalate)
- Loop detection is ADDITIONAL safety net
- Panic Button catches what loop detection misses
- Human escalation handles edge cases

**Secondary**: Learn from failures
```
memory_add_observation(
  entity="LoopDetectionFailures",
  observation="[DATE] Simple detection failed: [scenario] → Suggests need for [environment tracking/content hashing/etc]"
)
```

Review `LoopDetectionFailures` periodically → add complexity where proven necessary.

### Iteration Path (Based on Gemini Feedback)

**Priority 1 - If false positives occur**: Environment tracking
- Track cache hash (node_modules, dist/)
- Track .env hash
- Include in state comparison

**Priority 2 - If same-file issues**: File content hashing
- Hash file contents, not just names
- Detects line 45 vs line 46 changes

**Priority 3 - If longer loops observed**: Extended window
- Increase from 3 to 5-7 attempts
- Or graph-based cycle detection

**Priority 4 - If semantic loops waste time**: Error message analysis
- Include error message hash in state
- Same error + code changes = potential semantic loop

**Priority 5 - If whitespace causes issues**: AST comparison
- Compare syntax trees, not raw text
- Ignore formatting-only changes

**Decision criteria**: Add feature only when simple version demonstrably fails in practice.

---

## Simple Errors → Fail Forward

**Criteria**: Error is straightforward to fix
- Linting errors (missing semicolon, unused variable)
- Syntax errors (typo, missing bracket)
- Obvious bugs (wrong variable name, off-by-one)
- Import/module resolution (missing import statement)

**Process**:
1. Parse error message
2. Apply fix
3. Re-run verification
4. Max 3 attempts
5. If still failing → Escalate to Systematic Debugging

## Complex Errors → Systematic Debugging

**Criteria**: Error requires investigation
- Logic bugs (wrong output, unexpected behavior)
- Test failures (unclear why test fails)
- Integration issues (component interaction)
- Race conditions or timing issues
- Mysterious failures (no obvious cause)

**4-Phase Process**:

### Phase 1: Root Cause Investigation
- Examine error messages and stack traces thoroughly
- Reproduce consistently (identify exact steps)
- Review recent changes (git diff, git log)
- Add instrumentation at component boundaries
- Trace data flow backward to original source

### Phase 2: Pattern Analysis
- Find similar working code in codebase
- Compare working vs broken (all differences)
- Identify dependencies and assumptions
- Check for recent changes to dependencies

### Phase 3: Hypothesis and Testing
- Form specific hypothesis about root cause
- Test with minimal changes (one variable at a time)
- Verify results before proceeding

### Phase 4: Implementation
- Write failing test that reproduces bug
- Implement single targeted fix (address root cause, not symptom)
- Verify fix works without breaking other tests
- Document root cause and fix in commit message

**Escalation**: If 3 fixes fail → Question the architecture, not just the code. Trigger Panic Button.

## System Errors → Panic Button (Immediate)

**Criteria**: Environmental/infrastructure issues beyond code fixes
- Permission denied on files/directories
- Out of disk space
- Network timeout (git fetch/push)
- Memory exhaustion / OOM
- Corrupted git repository
- Authentication failure (expired tokens)
- Module resolution failure (missing deps, can't install)
- Database/service connectivity

**Process**:
1. **STOP** - Don't retry, don't attempt fixes
2. **Preserve state** - Keep checkpoint branches intact
3. **Gather diagnostics**:
   - Full error message (not truncated)
   - Environment details (disk space, network status)
   - Recent commands executed
   - Checkpoint branch name for recovery
4. **Report to Slack** with structured panic message
5. **Session ends** - Human intervention required

### Panic Report Format

```
❌ [ERROR TYPE] (Panic Button triggered)
Operation: [what was being attempted]
Error: [full error message]

Context:
- Repo: [owner/repo]
- Branch: [current branch]
- Task: [task description]
- Checkpoint: [checkpoint branch name if exists]

Attempts made: [what fixes were tried]
Root cause: [diagnosed cause if known]

Next: [what human needs to do]
```

## Memory Integration

After debugging session:
```
memory_add_observation(
  entity="FailurePatterns",
  observation="[DATE] PANIC/RESOLVED: [error type] → [root cause] → [fix applied] → [outcome]"
)
```

Before debugging similar error:
```
memory_query("Similar errors to [current error]")
→ Check FailurePatterns entity
→ Known root causes for this error type?
→ Successful fixes from past?
```
```

---

### 4. Memory Seed Updates

**File**: `config/memory-seed.json`

Add these entities to the existing structure:

```json
{
  "entities": [
    {
      "name": "ComplexityDecisions",
      "entityType": "execution_knowledge",
      "observations": [
        "Track brainstorming decisions and outcomes",
        "Format: [DATE] Task 'description' → [brainstormed/skipped] → [outcome] → [GOOD CALL/SHOULD HAVE X]"
      ]
    },
    {
      "name": "VerificationPatterns",
      "entityType": "execution_knowledge",
      "observations": [
        "Track verification approaches per file type",
        "Format: [file pattern] changes → [verification approach] → [worked/revealed issues]",
        "Example: src/api/*.ts → Integration tests required → Caught auth bug"
      ]
    },
    {
      "name": "SuccessfulWorkflows",
      "entityType": "execution_knowledge",
      "observations": [
        "Track end-to-end successful task completions",
        "Format: [Context] Task 'description' → [workflow steps] → PR merged [DATE]"
      ]
    },
    {
      "name": "FailurePatterns",
      "entityType": "execution_knowledge",
      "observations": [
        "Track panic situations and resolutions",
        "Format: [DATE] PANIC/RESOLVED: [error type] → [root cause] → [fix] → [outcome]",
        "Use for learning to avoid repeated failures"
      ]
    },
    {
      "name": "SessionProgress",
      "entityType": "session_state",
      "observations": [
        "Track attempts during current session for loop detection",
        "Format: Attempt [N]: [action] (files changed: [count]) → [result]",
        "Cleared after circuit breaker or session end",
        "Used by simple loop detector (v1)"
      ]
    },
    {
      "name": "LoopDetectionFailures",
      "entityType": "improvement_tracking",
      "observations": [
        "Track when simple loop detection fails",
        "Format: [DATE] Simple detection [missed loop/blocked valid retry]: [scenario] → Suggests [improvement needed]",
        "Review periodically to prioritize iteration path",
        "Examples: Environment change false positive → Add cache tracking"
      ]
    }
  ],
  "relations": [
    {"from": "ComplexityDecisions", "to": "SuccessfulWorkflows", "relationType": "informs"},
    {"from": "VerificationPatterns", "to": "SuccessfulWorkflows", "relationType": "validates"},
    {"from": "FailurePatterns", "to": "SystematicDebugging", "relationType": "prevents"},
    {"from": "HarvestSession", "to": "ComplexityDecisions", "relationType": "uses"},
    {"from": "HarvestSession", "to": "VerificationPatterns", "relationType": "uses"},
    {"from": "SessionProgress", "to": "LoopDetection", "relationType": "enables"},
    {"from": "LoopDetectionFailures", "to": "SessionProgress", "relationType": "improves"},
    {"from": "HarvestSession", "to": "SessionProgress", "relationType": "tracks_in"}
  ]
}
```

---

### 5. Finishing Workflow

**File**: `docs/ai/shared/finishing-workflow.md`

```markdown
# Finishing a Development Branch

Adapted from superpowers:finishing-a-development-branch skill.

## Pre-Check (MANDATORY)

Before presenting completion options:

```bash
# Run full test suite
npm test

# Check exit code
echo $?  # Must be 0
```

**BLOCKER**: Cannot proceed if tests fail. Fix failures first.

## 4 Completion Options

### Option 1: Merge to Base Branch Locally

**When**: Small internal tools, quick fixes not needing review

**Steps**:
1. Merge feature branch to base (e.g., main)
2. Run tests on merged result
3. Push merged base branch
4. Delete feature branch
5. Cleanup worktree (if used)

### Option 2: Push and Create Pull Request

**When**: Standard workflow (most common)

**Steps**:
1. Push feature branch to remote
2. Create PR using Harvest conventions (emojis, dad joke)
3. Reference plan PR number if applicable
4. Preserve branch for review
5. Report PR link to Slack

### Option 3: Keep Branch As-Is

**When**: Work in progress, need to pause

**Steps**:
1. Push current state (optional)
2. Preserve worktree
3. Document status in Slack
4. Agent can resume later

### Option 4: Discard This Work

**When**: Experimental work, dead end, no longer needed

**Steps**:
1. Require typed confirmation: "discard"
2. Delete feature branch
3. Cleanup worktree
4. Report discarded to Slack

**Safety**: Requires explicit confirmation to prevent accidental loss.

## Checkpoint Cleanup Timing

### On Success (Options 1 & 2)

After merge/PR creation confirmed:
```bash
# Delete all checkpoint branches created during session
git branch -D checkpoint-*

# Verify cleanup
git branch | grep checkpoint
# Should return nothing
```

### On Panic

**DO NOT cleanup** - preserve all checkpoint branches for human investigation.

Include checkpoint names in panic report.

### On Keep/Discard (Options 3 & 4)

Option 3: Leave checkpoints (work may resume)
Option 4: Cleanup checkpoints with branch deletion

## Memory Updates

After successful completion:
```
memory_add_observation(
  entity="SuccessfulWorkflows",
  observation="[Context] Task '[description]' → [workflow: brainstorm/skip → plan → execute → finish option] → PR merged/completed [DATE]"
)
```

After failure requiring panic:
```
memory_add_observation(
  entity="FailurePatterns",
  observation="[DATE] PANIC: [what failed] → Checkpoint: [branch name] → [diagnostic info]"
)
```
```

---

### 6. Hierarchical Planning

**Updates to**: `docs/ai/shared/planning.md`

Add this section:

```markdown
## Hierarchical Planning (New)

### Plan PR Contains High-Level Tasks

Plans created in Session 1 should have **5-10 high-level tasks** (30-60 min each).

**Example Plan PR Structure**:
```markdown
# Implementation Plan: Repository Classifier

## Task 1: Core Classification Logic (45 min)
- Implement classify() function with confidence scoring
- Handle edge cases (empty messages, ambiguous intent)
- Success: Function returns repo name + confidence score

## Task 2: Integration with Slack Bot (30 min)
- Add classifier to message handler
- Route to appropriate repo sandbox
- Success: Messages routed correctly in Slack

## Task 3: Testing & Verification (40 min)
- Unit tests for classifier
- Integration tests with mock Slack messages
- Success: All tests pass, coverage >80%
```

### Agent Breaks Down During Execution

During Session 2, agent dynamically expands each high-level task:

**Task 1 becomes**:
- 1.1: Write failing test for classify() (2 min)
- 1.2: Implement classify() basic logic (5 min)
- 1.3: Verify test passes (1 min)
- 1.4: Write failing test for confidence scoring (2 min)
- 1.5: Implement confidence scoring (4 min)
- 1.6: Verify test passes (1 min)
- 1.7: Write failing test for edge cases (3 min)
- 1.8: Implement edge case handling (5 min)
- 1.9: Verify test passes (1 min)
- 1.10: Run full test suite (2 min)
- 1.11: Commit completed task (1 min)

**Benefits**:
- Plan PR stays readable (not hundreds of tiny tasks)
- Agent has flexibility in execution approach
- Human reviews strategy, not micro-steps
- Scales to large features without context overflow
```

---

### 7. CLAUDE.md Updates

**Updates to**: `.claude/CLAUDE.md`

```markdown
## Superpowers Skills Integration

Harvest uses skills from the obra/superpowers framework. These are available via slash commands when the superpowers plugin is installed.

### Skill Usage Guide

**Complexity-Based Brainstorming**:
- Agent evaluates task complexity using `@docs/ai/shared/complexity-heuristic.md`
- Complex tasks → Invoke `/superpowers:brainstorming` for interactive design
- Simple tasks → Skip to autonomous planning

**Available Skills**:
- `/superpowers:brainstorming` - Interactive design validation (Session 1, complex tasks)
- `/superpowers:writing-plans` - Reference for plan format (informational)
- `/superpowers:test-driven-development` - Reference for TDD approach (informational)
- `/superpowers:systematic-debugging` - See `@docs/ai/shared/debugging.md` (integrated)
- `/superpowers:verification-before-completion` - See `@docs/ai/shared/verification.md` (integrated)
- `/superpowers:finishing-a-development-branch` - See `@docs/ai/shared/finishing-workflow.md` (integrated)

**Note**: Most superpowers concepts are integrated into Harvest's rules. Skills are referenced for specific workflows (brainstorming, finishing).
```

---

## Implementation Sequence

### Phase 1: Foundation Files (Can work in parallel)

1. Create `docs/ai/shared/complexity-heuristic.md`
2. Create `docs/ai/shared/verification.md`
3. Create `docs/ai/shared/debugging.md`
4. Create `docs/ai/shared/finishing-workflow.md`
5. Update `config/memory-seed.json` with new entities

### Phase 2: Integration Updates

6. Update `docs/ai/autonomous-agent.md` with two-session workflow
7. Update `docs/ai/local-development.md` with brainstorming guidance
8. Update `docs/ai/shared/planning.md` with hierarchical planning
9. Update `.claude/CLAUDE.md` with superpowers skill references

### Phase 3: Testing & Validation

10. Test complexity evaluation (does agent correctly decide to brainstorm?)
11. Test hierarchical planning (are plans readable and executable?)
12. Test verification loops (does advisory hook work correctly?)
13. Test debugging escalation (fail-forward → systematic → panic)
14. Test memory updates (are patterns being learned?)
15. Test finishing workflow (all 4 options work correctly?)

---

## Success Criteria

### Session 1 (Planning)

- ✅ Agent correctly evaluates complexity (queries memory, applies heuristic)
- ✅ Interactive brainstorming when needed (presents options, gets feedback)
- ✅ Plans follow hierarchical structure (5-10 high-level tasks)
- ✅ Plan PRs are readable and reviewable
- ✅ Memory updated with complexity decision + outcome

### Session 2 (Execution)

- ✅ Agent breaks down high-level tasks dynamically
- ✅ Verification loops work (tests for logic, appropriate checks for non-logic)
- ✅ Debugging escalates correctly (simple → complex → panic)
- ✅ Tests pass before finishing workflow
- ✅ 4 completion options presented correctly
- ✅ Checkpoints cleaned up on success, preserved on panic
- ✅ Memory updated with execution patterns and outcomes

### Memory Learning

- ✅ ComplexityDecisions entity populated with task outcomes
- ✅ VerificationPatterns entity tracks what works per file type
- ✅ SuccessfulWorkflows entity documents end-to-end completions
- ✅ FailurePatterns entity captures panics and resolutions
- ✅ Agent queries memory before decisions (complexity, verification)
- ✅ Agent updates memory after outcomes

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| **Agent misclassifies complexity** | Skips brainstorming when needed, or over-brainstorms simple tasks | Memory learning + manual override option |
| **Hierarchical planning too abstract** | Agent struggles to break down during execution | Provide examples in planning.md, iterate based on outcomes |
| **Advisory hook too noisy** | Developers ignore warnings | Tune exemption patterns, focus on high-risk only |
| **Memory grows unbounded** | Context overflow, slow queries | Implement memory pruning (keep last 50 observations per entity) |
| **Systematic debugging too slow** | Wastes time on simple errors | Clear criteria for when to use (complex errors only) |
| **Finishing options confusing** | Agent picks wrong option | Clear decision criteria per option in finishing-workflow.md |

---

## Open Questions

1. **Memory pruning strategy**: How many observations to keep per entity? Time-based or count-based?
2. **Brainstorming timeout**: Max time for interactive brainstorming before auto-proceeding?
3. **Pre-commit hook implementation**: Git hook or separate script? How to install?
4. **Testing hierarchical planning**: Need real complex feature to validate breakdown works?
5. **Modal resource monitoring**: How to track disk usage from checkpoints, ensure cleanup works?
6. **Loop detection monitoring**: How to track LoopDetectionFailures? Dashboard? Periodic review cadence?
7. **SessionProgress cleanup**: Clear on session end, or keep for cross-session learning?

---

## Future Enhancements (Not in Scope)

- Git worktrees support (local development only, superpowers skill available)
- Parallel agent dispatch (subagent-driven-development for independent tasks)
- Advanced plan templates (domain-specific templates for common patterns)
- Automated plan quality scoring (analyze plans for completeness before PR)
