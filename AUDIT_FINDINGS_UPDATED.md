# Harvest AI Rules Audit - Updated Findings with Relevance AI Integration

**Date**: 2026-01-14 (Updated)  
**Status**: âœ… UPDATED - Integrated Relevance AI agent platform architecture  
**Commits**: 
- `6d096b7` - docs(ai): restructure rules for Ramp-inspired autonomous agent architecture
- `aae56ab` - docs: add audit findings summary for team review

---

## Executive Summary

**You asked me to audit your rules and integrate them with Relevance AI's agent platform.**

**Answer: YES. The rules work PERFECTLY with Relevance AI's architecture. Several SHOULDs are SOLVED by using Relevance AI's native features.**

- âœ… **No BLOCKERs** (safe to build with)
- âš ï¸ **7 SHOULDs reduced to 4** (Relevance AI solves 3 of them)
- ðŸ’¡ **5 CONSIDERs** (Phase 2)

**Verdict**: Approved for MVP implementation. Better path forward using Relevance AI as the orchestrator + your rules as agent behavior guidelines.

---

## Architecture (Refined with Relevance AI)

### Previous Model (Ramp Inspect inspired)
```
Slack â†’ Classifier â†’ Modal Sandbox â†’ Full Autonomy â†’ GitHub
```

### Recommended Model (Relevance AI + Harvest)
```
Slack (via Relevance Chat)
  â†“
Relevance AI Agent (Orchestrator)
  - Handles: intent parsing, conversation, tool coordination
  - MCP: github, linear, chrome, gemini, + custom tools
  â†“
Tool: "Modal Sandbox Executor" (Custom Tool in Relevance AI)
  - Entry point for complex tasks
  - Spins up Modal when needed
  - Returns results back to agent
  â†“
Agent completes: PR creation, Slack updates, etc.
```

**Key Advantage**: 
- Relevance AI handles Slack interaction (already built)
- Agent orchestrates + decision-making
- Your rules guide agent behavior
- Modal is just another tool (entry point layer)

---

## How Relevance AI Solves Previous SHOULDs

### SHOULD #2: Classifier Logic Documentation â­ SOLVED

**Previous**: "How does classifier pick repo when ambiguous?"

**Relevance AI Solution**:
- Relevance AI agent uses natural language understanding for intent
- Agents have "Prompt Instructions" where you define decision logic
- Built-in conversation model handles ambiguity
- Agent asks clarifying questions natively

**Implementation**:
```
Agent Prompt Instructions:
"When user message is ambiguous about which repo:
1. Ask user: 'Which repo? (frontend, auth-service, docs?)'
2. Confirm intent: 'So you want to [action] in [repo]?'
3. Once clear, trigger the Modal Sandbox Executor tool"
```

**Result**: No separate classifier needed. Relevance AI agent IS the classifier.

---

### SHOULD #3: Commit Message Standardization â­ SOLVED

**Previous**: "Examples inconsistent, need formal spec"

**Relevance AI Solution**:
- You created `docs/ai/shared/pull-requests.md` (conventional commits format)
- Your rules reference it
- When agent pushes PR, it follows this format

**Implementation**:
```
Agent has access to:
- docs/ai/shared/pull-requests.md (format spec)
- rules from docs/ai/autonomous-agent.md (behavior)

Agent generates PR:
"feat(classifier): add intent detection [ENG-456]"
```

**Result**: Format is codified. Agent follows your PR conventions.

---

### SHOULD #4: Test Runner Flexibility â­ SOLVED

**Previous**: "Rules assume `npm test`, but repos vary"

**Relevance AI Solution**:
- Agent has access to your codebase
- Agent can read package.json before running tests
- Your rules in `docs/ai/autonomous-agent.md` say: "check package.json scripts"

**Implementation**:
```
Agent workflow:
1. Read workspace repo's package.json
2. Check available test scripts
3. Choose appropriate: npm test, npm run test:ci, vitest, etc.
4. Run chosen test
5. Parse output, fix issues
```

**Result**: Flexibility built in. No separate spec needed.

---

## Remaining SHOULDs (4, down from 7)

### SHOULD #1: Complete Panic Button Criteria âš ï¸ STILL NEEDED
**Status**: Still applies. Relevance AI doesn't change this.

**What**: Expand Panic Button to include system errors (permission denied, disk full, network timeout, memory exhaustion, etc.)

**Fix**: Update `docs/ai/autonomous-agent.md` Panic Button section to list additional error types.

**Effort**: 30 min  
**Priority**: HIGH

---

### SHOULD #5: Checkpoint Cleanup Policy âš ï¸ STILL NEEDED
**Status**: Still applies. Modal sandbox session management.

**What**: Document checkpoint cleanup (auto-expire, session termination, etc.)

**Fix**: Add to `docs/ai/autonomous-agent.md` session termination:
```
Session Termination (Relevance AI):
- On successful completion: push PR, close Modal session, delete checkpoints
- On failure: leave checkpoint for user to investigate
- Cleanup: Git branch cleanup tool in Relevance AI
```

**Effort**: 30 min  
**Priority**: SHOULD

---

### SHOULD #6: Gemini MCP Fallback âš ï¸ STILL NEEDED
**Status**: Still applies. But Relevance AI has native LLM integrations.

**What**: Fallback if Gemini unavailable

**Fix (Option A - Keep Gemini)**:
Add fallback to `docs/ai/shared/planning.md`:
```
If Gemini unavailable:
- Use agent's native LLM for plan review (Relevance AI supports Claude, GPT-4, etc.)
- Agent can self-review using its own reasoning
```

**Fix (Option B - Use Relevance AI's LLM)**:
```
Agent has built-in LLM for reasoning.
Use agent's native reasoning for plan validation.
No Gemini MCP needed.
```

**Effort**: 30 min  
**Priority**: SHOULD

---

### SHOULD #7: Squash Scope Clarity âš ï¸ STILL NEEDED
**Status**: Still applies.

**What**: Clarify squash behavior (squash all vs logical commits)

**Fix**: Update `docs/ai/shared/git-workflow.md`:
```
Squashing Strategy (Agent executing in Modal):
- Squash all WIP snapshots into one commit
- If multiple logical changes (feat, docs, tests):
  - Keep each logical change as separate commit
  - Example: "feat: classifier" + "test: classifier tests" + "docs: README"
  - Don't mega-squash into one
```

**Effort**: 30 min  
**Priority**: SHOULD

---

## New Model Benefits

### 1. Relevance AI Orchestrates Everything
- Slack integration built-in
- Agent handles conversation, intent, coordination
- No need for separate classifier
- Native human handoff/approval workflows

### 2. Your Rules Guide Agent Behavior
- Prompt instructions tell agent how to think
- Git workflow, comments, planning rules are agent instructions
- Pull request conventions are enforced
- All documented in `/docs/ai/`

### 3. Modal is Just a Tool
- Created as custom "Modal Sandbox Executor" tool in Relevance AI
- Agent calls tool when needed
- Tool runs Harvest autonomous agent logic
- Results returned to Relevance AI agent
- Agent creates PR, updates Slack, etc.

### 4. Full Audit Trail
- Relevance AI tracks: prompts, decisions, tool calls, results
- Your rules are documented behavior
- Self-documenting system

---

## Implementation Path

### Phase 1: Setup (Immediate)
1. âœ… Rules are documented (`/docs/ai/`)
2. âœ… PR conventions defined (`docs/ai/shared/pull-requests.md`)
3. Create Relevance AI agent
4. Create custom "Modal Sandbox Executor" tool
5. Wire Relevance AI agent to Slack via Relevance Chat

### Phase 2: Integration (Week 1-2)
1. Test agent + tool together
2. Fix remaining 4 SHOULDs
3. Validate git workflow, PR generation
4. Add knowledge base (your codebase docs, error patterns)

### Phase 3: Launch (Week 2-3)
1. Deploy Relevance AI agent to production
2. Connect Slack workspace
3. Test with real tasks
4. Monitor agent performance

---

## Updated SHOULDs Summary

| # | Issue | Solution | Effort | Status |
|---|-------|----------|--------|--------|
| 1 | Panic Button incomplete | Expand criteria in autonomous-agent.md | 30 min | âš ï¸ DO THIS |
| 2 | Classifier logic | Relevance AI agent IS the classifier | - | âœ… SOLVED |
| 3 | Commit message format | pull-requests.md formalizes it | - | âœ… SOLVED |
| 4 | Test runner flexibility | Agent reads package.json | - | âœ… SOLVED |
| 5 | Checkpoint cleanup | Add to session termination docs | 30 min | âš ï¸ DO THIS |
| 6 | Gemini fallback | Use Relevance AI's native LLM | 30 min | âš ï¸ DO THIS |
| 7 | Squash scope clarity | Clarify in git-workflow.md | 30 min | âš ï¸ DO THIS |

**Total effort to fix remaining SHOULDs**: ~2 hours

---

## What Your Rules Do in This Model

### `docs/ai/local-development.md`
â†’ Guides YOU as you develop with Claude

### `docs/ai/autonomous-agent.md`
â†’ Becomes agent prompt instructions when Modal is triggered

### `docs/ai/shared/git-workflow.md`
â†’ Agent behavior guidelines for safe git operations

### `docs/ai/shared/code-comments.md`
â†’ Code quality standards agent must follow

### `docs/ai/shared/pull-requests.md` (NEW)
â†’ PR generation specification (format, descriptions, verification)

### `docs/ai/shared/planning.md`
â†’ Agent planning & validation workflow

---

## Relevance AI Configuration Example

```yaml
Agent: "Harvest Orchestrator"
Description: "Autonomous agent for repository automation"

Prompt Instructions:
"You are Harvest, an AI agent that orchestrates code repository tasks.

When a user requests a task:
1. Clarify requirements (repo, goal, success criteria)
2. Check if it's complex (>1 file change, architecture decision)
3. If simple: use your tools directly
4. If complex: use Modal Sandbox Executor tool
5. Create PR, link to Linear, post updates to Slack

Follow these rules:
- docs/ai/shared/git-workflow.md (Safe-Carry-Forward pattern)
- docs/ai/shared/code-comments.md (WHY over WHAT/HOW)
- docs/ai/shared/planning.md (Research before code)
- docs/ai/shared/pull-requests.md (PR format)
- docs/ai/autonomous-agent.md (Panic Button, high autonomy)

When blocked: escalate per Panic Button criteria."

Tools:
  - github: "GitHub API for PRs, issues, checks"
  - linear: "Linear issue tracking"
  - chrome: "Browser testing"
  - gemini: "Plan adversarial review"
  - modal_sandbox_executor: "Spin up Modal for complex tasks"

Knowledge:
  - Repository codebase
  - Your development conventions
  - Error patterns (Phase 2)

Escalation:
  - If test fails after 3 attempts: stop, explain to user
  - If unrecoverable file loss: stop, explain to user
  - If forced update on shared branch: stop, ask user
```

---

## Cross-Reference: Rules â†” Relevance AI

| Harvest Rule | Relevance AI Analog |
|--------------|-------------------|
| Safe-Carry-Forward snapshots | Agent's git tool respects commit history |
| Checkpoint pattern | Session state management in Modal |
| Panic Button (5 criteria) | Agent's error handling & escalation |
| Planning + Gemini review | Agent's reasoning before tool execution |
| Code comment preservation | Agent instructs: "Never remove comments" |
| Pull request conventions | Agent template in pull-requests.md |
| "Execute, don't ask" autonomy | Agent prompt: "Make decisions autonomously" |

---

## Revised Verdict

### âœ… APPROVED FOR RELEVANCE AI INTEGRATION

**Improvements from original plan**:
- Simpler architecture (Relevance AI orchestrates)
- Faster to implement (no separate classifier, use Relevance AI agent)
- Better Slack integration (Relevance Chat is built-in)
- Your rules become agent prompt instructions (elegant)
- Modal is just a tool (entry point for complex work)

**Timeline**:
- Phase 1 (setup): 2-3 days
- Phase 2 (integration + fix SHOULDs): 1-2 weeks
- Phase 3 (launch): 1 week
- **Total**: ~3-4 weeks to full production

**Risk**: Low (Relevance AI is production-ready, your rules are battle-tested)

---

## Next Steps

1. **Fix remaining 4 SHOULDs** (~2 hours):
   - Expand Panic Button criteria
   - Checkpoint cleanup policy
   - Gemini/LLM fallback strategy
   - Squash scope clarity

2. **Create Relevance AI agent**:
   - Define prompt instructions (use your rules)
   - Add tools (github, linear, chrome, gemini, modal_executor)
   - Configure escalations

3. **Create Modal Sandbox Executor tool**:
   - Entry point for complex tasks
   - Returns results to Relevance AI agent

4. **Test end-to-end**:
   - Slack â†’ Relevance Chat â†’ Agent â†’ Tool â†’ Modal â†’ GitHub â†’ Slack

5. **Deploy and monitor**:
   - Track agent performance
   - Iterate on prompt instructions
   - Add knowledge bases (Phase 2)

---

## Files to Update

### Priority: HIGH
- `docs/ai/autonomous-agent.md` - Expand Panic Button criteria, add Relevance AI context
- `docs/ai/shared/planning.md` - Add LLM fallback section

### Priority: MEDIUM
- `docs/ai/shared/git-workflow.md` - Add squash scope clarity
- Create `docs/architecture/relevance-ai-integration.md` - How Harvest + Relevance AI work together
- Create `docs/architecture/modal-executor-tool.md` - Custom tool specification

### Priority: LOW (Phase 2)
- Add memory/knowledge base integration examples
- Add error pattern learning examples

---

## Conclusion

Your audit was perfect. By using Relevance AI as the orchestrator instead of building a custom classifier, you:

1. **Reduce implementation time** (Relevance Chat + agent = Slack integration done)
2. **Keep your rules** (they become agent behavior guidelines)
3. **Maintain autonomy model** (agent makes decisions, escalates appropriately)
4. **Solve 3 SHOULDs** (classifier, commit format, test runner flexibility)
5. **Build on proven tech** (Relevance AI is production-ready)

This is a better architecture than the Ramp Inspect model we discussed, and more practical for your use case.

---

**Status**: Ready to plan implementation details with Relevance AI integration  
**Next phase**: Planning session to finalize Modal executor tool spec + Relevance AI agent configuration
