# Implementation Plan: Harvest Interactive PTY Sessions with Message Queuing

**Date:** 2026-01-17
**Branch:** feat/harvest-pty-interactive-sessions
**Status:** Planning
**Related PR:** https://github.com/RelevanceAI/relevance-api-node/pull/10748

## Executive Summary

Implement persistent interactive Claude Code CLI sessions using PTY with message queuing and bidirectional streaming for Relevance Chat UI integration. This enables true conversational context preservation across multiple prompts while maintaining the dual-pane Chat UI experience (left: user input, right: terminal viewer).

**Key Decision:** Use PTY-based interactive Claude CLI with Stop hook detection for message queuing, matching how Claude Code CLI works natively.

## Research Findings

### 1. Claude CLI Interactive Mode Support

**Confirmed capabilities:**
- ✅ Interactive mode supports stdin-based prompting (no `--print` flag)
- ✅ Stop hook fires in interactive mode when response completes
- ✅ Maintains conversation context across multiple prompts in same process
- ✅ Supports graceful cancellation via SIGINT (Ctrl+C)

**Source:** [Gemini Deep Research](../../../docs/research/claude-cli-pty-investigation.md), [Claude Code Hooks Documentation](https://code.claude.com/docs/en/hooks)

### 2. Streaming to Chat UI

**Pattern from Github Coder:**
```typescript
// Tools return objects with stdout/stderr
return {
  stdout: result.result,  // Automatically shown in right pane (toolviewer)
};
```

**Harvest implementation:**
```typescript
export const HarvestRuntime = async (convo: ConversationManager) => {
  for await (const chunk of harvestProcess.stdout) {
    yield { stdout: chunk };  // Shows in right pane
  }
};
```

**Finding:** ConversationManager already handles tool output streaming to toolviewer. No UI changes needed.

### 3. Session Model for Agentic Swarms

**Decision:** `conversation_id === session_id`

**Rationale:**
- Modal scales horizontally (10-50 concurrent sandboxes is trivial)
- Clean isolation per conversation (no cross-contamination)
- Simpler debugging and state management
- Aligns with existing Relevance patterns

**Trade-off:** More cold starts vs complexity of sandbox reuse. Choose simplicity.

### 4. Modal Container Lifecycle

**Timeout strategy (two types):**
```python
@app.function(
    scaledown_window=300,  # 5 min idle timeout (no user messages)
    min_containers=0,      # Don't keep warm (save costs)
    memory=6144,           # 6GB (Claude + Node + Python processes)
    timeout=43200,         # 12 hour session timeout (supports overnight tasks)
)
```

**Timeout types:**
1. **Idle timeout (5 min)**: When user sends NO messages, container shuts down to save costs. Conversation history saved to SQLite.
2. **Session timeout (12 hours)**: Maximum duration for a single task. Supports overnight work like "refactor entire auth system".

**Performance characteristics:**
- Cold start with memory snapshots: <3 seconds
- Warm start: ~instant
- Idle cost: ~$0.10/hour per container
- Terminated + cold start: ~$0.02/hour per user

**Decision:** Terminate at 5 minutes idle (no messages), but allow up to 12 hours for active long-running tasks. Saves ~80% compute cost with acceptable <3s cold start penalty.

**Sources:**
- [Modal Cold Start Performance](https://modal.com/docs/guide/cold-start)
- [Modal Timeouts](https://modal.com/docs/guide/timeouts)
- [Modal Memory Snapshots](https://modal.com/blog/comfyui-mem-snapshots)

### 5. CORS and API Routing

**Pattern:** Route through Relevance API (server-to-server)

```
Chat UI → Relevance API → Modal
   ✅         ✅            ✅
```

**Why:**
- No CORS configuration needed
- Centralized auth (Modal tokens server-side)
- Consistent with existing patterns (Github Coder)
- Simpler debugging

### 6. Memory Leak Mitigation

**Known issue:** Claude CLI can leak memory (tens of GBs) in long sessions

**Mitigations:**
1. **Container memory limit:** 6GB hard cap (Modal terminates if exceeded)
2. **Session timeout:** 12 hours max (supports overnight tasks like "refactor auth system")
3. **Idle timeout:** 5 minutes when no messages sent (restarts PTY, clears memory)
4. **Memory monitoring:** If usage >5GB, save checkpoint, restart PTY, restore context

**Monitoring:**
```python
async def _get_memory_mb(self) -> int:
    result = await self._get_sandbox().exec.aio("cat", "/proc/self/status")
    # Parse VmRSS to get current memory usage
```

## Architecture

### System Overview

```
┌─────────────────────────────────────────────────────────────────┐
│ External Triggers (Slack, GitHub webhooks, Chat UI)             │
└────────────────────┬────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│ Relevance Sync/Trigger Infrastructure                           │
│  • TriggerRunner (buffer, deduplication)                        │
│  • ConversationManager (streaming to toolviewer)                │
└────────────────────┬────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│ BackgroundCoderPresetAgent (TypeScript)                         │
│  • HarvestRuntime (spawns Python subprocess)                    │
│  • Streams stdout → ConversationManager → Right pane            │
│  • conversation_id → session_id mapping                         │
└────────────────────┬────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│ harvest-client (Python subprocess)                              │
│  • Thin wrapper around HarvestSandbox                           │
│  • JSON streaming over stdout                                   │
│  • Modal auth via token                                         │
└────────────────────┬────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│ HarvestSandbox (Modal Container)                                │
│  • Claude CLI in PTY (interactive mode)                         │
│  • Message queue (async.Queue)                                  │
│  • Stop hook detection (<<<CLAUDE_DONE>>>)                      │
│  • Memory monitoring                                             │
│  • Session state (SQLite on Modal Volume)                       │
└─────────────────────────────────────────────────────────────────┘
```

### Chat UI Experience

```
┌─────────────────────────────────────────────────────────────────┐
│ Chat UI (relevance-chat-app)                                    │
├──────────────────────────┬──────────────────────────────────────┤
│ LEFT PANE: Input         │ RIGHT PANE: Terminal Viewer          │
│                          │ (xterm.js - read-only, copyable)     │
│ User: Fix the tests      │                                      │
│                          │ > Analyzing test failures...         │
│ [Send] [Cancel]          │ > Running: npm test                  │
│                          │ >                                    │
│                          │ > FAIL src/classifier.test.ts        │
│                          │ >   ● Expected 'foo' but got 'bar'   │
│                          │ >                                    │
│                          │ > I'll fix the type mismatch...      │
│                          │ > Running: git add src/classifier.ts │
│                          │ > Running: git commit -m "fix: ..."  │
│                          │ >                                    │
│                          │ > <<<CLAUDE_DONE>>>                  │
└──────────────────────────┴──────────────────────────────────────┘
```

### Message Queuing Flow

```
User sends: "Fix the tests"
  ↓
Queue message → PTY.write("Fix the tests\n")
  ↓
Claude processes, outputs to PTY
  ↓
Stream chunks to stdout (parsed by harvest-client)
  ↓
ConversationManager shows in right pane
  ↓
Stop hook fires: <<<CLAUDE_DONE>>>
  ↓
Next queued message (if any) sent to PTY

User sends: "Also add type hints" (while Claude is still working on first)
  ↓
Queued in asyncio.Queue
  ↓
Waits for Stop hook from first message
  ↓
Automatically sent to same PTY (maintains context)
```

### Cancellation Flow

```
User clicks "Cancel" button in Chat UI
  ↓
Chat UI → POST /api/agents/harvest/cancel/:conversation_id
  ↓
Relevance API → Modal cancel endpoint
  ↓
Modal sandbox receives cancel request
  ↓
Send Ctrl+C to PTY (os.kill(proc.pid, signal.SIGINT))
  ↓
Claude stops mid-execution
  ↓
Stop hook still fires (graceful termination)
  ↓
Next queued message (if any) gets sent
```

## Implementation Phases

### Phase 1: PTY Infrastructure (Harvest Repo)

**Goal:** Add interactive Claude CLI support with message queuing and Stop hook detection

**Files to modify:**

#### 1.1 `packages/modal-executor/src/modal_executor/sandbox.py`

**Changes:**
```python
import asyncio
import os
import pty
import signal
from typing import AsyncIterator

class HarvestSandbox:
    def __init__(self, session: HarvestSession):
        self.session = session
        self.claude_pty: Optional[PTYWrapper] = None
        self.message_queue = asyncio.Queue()
        self._processing_task: Optional[asyncio.Task] = None
        self._shutdown_requested = False

    async def start(self, timeout_secs: int = 43200):
        """Start sandbox with PTY-based Claude CLI (12-hour session timeout)"""
        # ... existing setup (git, clone, etc.) ...

        # Start Claude in interactive mode
        await self._start_claude_pty()

        # Start message processor
        self._processing_task = asyncio.create_task(
            self._process_message_queue()
        )

        return self

    async def _start_claude_pty(self):
        """Spawn Claude CLI in PTY with Stop hook"""
        # Create PTY
        master, slave = pty.openpty()

        # Configure settings with Stop hook
        await self._write_settings_with_stop_hook()

        # Spawn claude (interactive mode, no --print)
        proc = await asyncio.create_subprocess_exec(
            "claude",
            "--dangerously-skip-permissions",
            stdin=slave,
            stdout=slave,
            stderr=slave,
            env={
                "CLAUDE_CODE_OAUTH_TOKEN": self.session.claude_oauth_token,
                "HOME": "/root",
            }
        )

        self.claude_pty = PTYWrapper(master, slave, proc)
        logger.info("Claude PTY started successfully")

    async def _write_settings_with_stop_hook(self):
        """Create settings.json with Stop hook marker"""
        config = {
            "permissions": {"allow": ["*"], "defaultMode": "bypassPermissions"},
            "hooks": {
                "Stop": [{
                    "hooks": [{
                        "type": "command",
                        "command": "echo '<<<CLAUDE_DONE>>>'"
                    }]
                }],
                "SessionStart": [{
                    "hooks": [
                        {"type": "command", "command": "cat /app/claude.md"},
                        {"type": "command", "command": "cat /app/autonomous-agent.md"}
                    ]
                }]
            },
            "enabledPlugins": {"superpowers@claude-plugins-official": True}
        }
        await self._write_json_atomic("/root/.claude/settings.json", config)

    async def send_prompt(self, prompt: str):
        """Queue a prompt (non-blocking)"""
        await self.message_queue.put(prompt)
        logger.info(f"Prompt queued: {prompt[:50]}...")

    async def _process_message_queue(self):
        """Process queued messages sequentially"""
        while not self._shutdown_requested:
            try:
                prompt = await asyncio.wait_for(
                    self.message_queue.get(),
                    timeout=1.0
                )
            except asyncio.TimeoutError:
                # Check if we should shutdown due to idle timeout
                if await self._should_shutdown_idle():
                    logger.info("Idle timeout reached, shutting down PTY")
                    break
                continue

            # Send to PTY
            await self.claude_pty.write(f"{prompt}\n")

            # Stream until Stop hook
            async for chunk in self._read_until_stop_hook():
                # Write to stdout for harvest-client to capture
                print(chunk, end="", flush=True)

            # Save exchange to session state
            if self.session_state:
                # Full response collected during _read_until_stop_hook
                self.session_state.add_exchange(prompt, self._last_response)

    async def _read_until_stop_hook(self) -> AsyncIterator[str]:
        """Read PTY output until Stop hook marker appears"""
        self._last_response = []

        while True:
            chunk = await self.claude_pty.read(timeout=1800)  # 30 min per chunk

            if "<<<CLAUDE_DONE>>>" in chunk:
                # Strip marker before yielding
                clean_chunk = chunk.replace("<<<CLAUDE_DONE>>>", "")
                if clean_chunk:
                    self._last_response.append(clean_chunk)
                    yield clean_chunk
                break

            self._last_response.append(chunk)
            yield chunk

        self._last_response = "".join(self._last_response)

    async def cancel_current(self):
        """Send Ctrl+C to PTY to cancel current execution"""
        if self.claude_pty and self.claude_pty.proc:
            logger.info("Sending SIGINT to Claude PTY")
            os.kill(self.claude_pty.proc.pid, signal.SIGINT)

    async def _should_shutdown_idle(self) -> bool:
        """Check if PTY should shut down due to idle timeout"""
        if not hasattr(self, '_last_activity_time'):
            self._last_activity_time = time.time()
            return False

        idle_seconds = time.time() - self._last_activity_time
        return idle_seconds > 300  # 5 minutes

    async def _get_memory_mb(self) -> int:
        """Get current memory usage in MB"""
        if not self.sandbox:
            return 0

        proc = await self.sandbox.exec.aio("cat", "/proc/self/status")
        status = proc.stdout.read()

        # Parse VmRSS line
        for line in status.split("\n"):
            if line.startswith("VmRSS:"):
                kb = int(line.split()[1])
                return kb // 1024

        return 0

    async def terminate(self):
        """Gracefully terminate sandbox and PTY"""
        self._shutdown_requested = True

        # Wait for message processor to finish
        if self._processing_task:
            await self._processing_task

        # Close PTY
        if self.claude_pty:
            self.claude_pty.close()

        # ... existing cleanup ...
```

#### 1.2 `packages/modal-executor/src/modal_executor/pty_wrapper.py`

**New file:**
```python
"""PTY wrapper for bidirectional communication with subprocess"""
import asyncio
import os
import select
from typing import Optional

class PTYWrapper:
    """Manages PTY communication with subprocess"""

    def __init__(self, master: int, slave: int, proc: asyncio.subprocess.Process):
        self.master = master
        self.slave = slave
        self.proc = proc

    async def write(self, data: str):
        """Write to PTY stdin"""
        os.write(self.master, data.encode())

    async def read(self, timeout: int = 30) -> str:
        """Read from PTY stdout with timeout"""
        loop = asyncio.get_event_loop()

        def _read_ready():
            return select.select([self.master], [], [], 0)[0]

        # Wait for data with timeout
        deadline = asyncio.get_event_loop().time() + timeout
        while asyncio.get_event_loop().time() < deadline:
            if _read_ready():
                data = os.read(self.master, 4096)
                return data.decode('utf-8', errors='replace')
            await asyncio.sleep(0.1)

        raise asyncio.TimeoutError("PTY read timeout")

    def close(self):
        """Close PTY file descriptors"""
        try:
            os.close(self.master)
            os.close(self.slave)
        except OSError:
            pass
```

#### 1.3 `packages/modal-executor/src/modal_executor/app.py`

**Add cancel endpoint:**
```python
@app.function()
async def cancel_session(session_id: str):
    """Cancel the current prompt in a running session

    Args:
        session_id: The conversation/session ID

    Returns:
        {"success": True} if cancelled, {"success": False, "error": "..."} otherwise
    """
    # Get running sandbox from registry
    sandbox = _get_running_sandbox(session_id)

    if sandbox:
        await sandbox.cancel_current()
        return {"success": True}

    return {"success": False, "error": "Session not found or already terminated"}

# Session registry (in-memory, per Modal container)
_active_sandboxes: dict[str, HarvestSandbox] = {}

def _register_sandbox(session_id: str, sandbox: HarvestSandbox):
    """Register active sandbox for cancellation"""
    _active_sandboxes[session_id] = sandbox

def _unregister_sandbox(session_id: str):
    """Unregister sandbox when terminated"""
    _active_sandboxes.pop(session_id, None)

def _get_running_sandbox(session_id: str) -> Optional[HarvestSandbox]:
    """Get active sandbox by session ID"""
    return _active_sandboxes.get(session_id)
```

#### 1.4 `packages/modal-executor/src/modal_executor/images.py`

**Update memory limits:**
```python
def get_base_image() -> modal.Image:
    """Base image with Claude Code CLI, Node, Python, and MCP servers"""
    return (
        modal.Image.debian_slim(python_version="3.11")
        # ... existing setup ...
    )

# Update function decorator
@app.function(
    image=get_base_image(),
    memory=6144,              # 6GB for Claude + Node + Python
    scaledown_window=300,     # 5 min idle timeout (no messages)
    min_containers=0,         # Don't keep warm
    timeout=43200,            # 12 hour session timeout (overnight tasks)
)
```

### Phase 2: harvest-client Package (Harvest Repo)

**Goal:** Create thin Python wrapper for external consumption

**Files to create:**

#### 2.1 `packages/harvest-client/pyproject.toml`

```toml
[project]
name = "harvest-client"
version = "0.1.0"
description = "Client library for Harvest background coding agent"
requires-python = ">=3.11"
dependencies = [
    "modal>=0.63.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

#### 2.2 `packages/harvest-client/src/harvest_client/__init__.py`

```python
from .client import HarvestClient
from .session import HarvestSessionConfig

__all__ = ["HarvestClient", "HarvestSessionConfig"]
```

#### 2.3 `packages/harvest-client/src/harvest_client/client.py`

```python
"""Harvest client for spawning Modal sandboxes"""
import asyncio
from typing import AsyncIterator

import modal

from .session import HarvestSessionConfig

class HarvestClient:
    """Client for interacting with Harvest Modal sandboxes"""

    def __init__(self, modal_token_id: str, modal_token_secret: str):
        """Initialize client with Modal credentials"""
        self.modal_token_id = modal_token_id
        self.modal_token_secret = modal_token_secret

        # Authenticate with Modal
        modal.config.set_credentials(modal_token_id, modal_token_secret)

    async def send_prompt_stream(
        self,
        session_id: str,
        prompt: str,
        config: HarvestSessionConfig
    ) -> AsyncIterator[str]:
        """Send prompt and stream response

        Args:
            session_id: Conversation ID (used as Modal session ID)
            prompt: User prompt
            config: Session configuration (repo, credentials, etc.)

        Yields:
            Response chunks from Claude CLI
        """
        # Import Modal function
        from modal_executor.app import send_prompt as modal_send_prompt

        # Call Modal function (spawns sandbox if needed)
        async for chunk in modal_send_prompt.remote_gen(
            session_id=session_id,
            prompt=prompt,
            repo_owner=config.repo_owner,
            repo_name=config.repo_name,
            github_token=config.github_token,
            claude_oauth_token=config.claude_oauth_token,
            gemini_api_key=config.gemini_api_key,
            # ... other credentials
        ):
            yield chunk

    async def cancel(self, session_id: str):
        """Cancel current execution

        Args:
            session_id: Conversation ID
        """
        from modal_executor.app import cancel_session

        result = await cancel_session.remote(session_id)
        return result
```

#### 2.4 `packages/harvest-client/src/harvest_client/session.py`

```python
"""Session configuration for Harvest"""
from dataclasses import dataclass, field
from typing import Optional

@dataclass
class HarvestSessionConfig:
    """Configuration for a Harvest agent session"""

    session_id: str
    repo_owner: str
    repo_name: str
    branch: str = "main"

    # Git identity
    user_email: str = ""
    user_name: str = ""

    # Required credentials (excluded from repr)
    github_token: str = field(repr=False)
    claude_oauth_token: str = field(repr=False)

    # Optional credentials
    gemini_api_key: Optional[str] = field(default=None, repr=False)
    sentry_auth_token: Optional[str] = field(default=None, repr=False)
    linear_api_key: Optional[str] = field(default=None, repr=False)
```

### Phase 3: Relevance Integration (relevance-api-node)

**Goal:** Create BackgroundCoderPresetAgent using HarvestRuntime

**Files to create:**

#### 3.1 `apps/nodeapi/src/agent/preset_agents/background_coder/agent.ts`

```typescript
import { PresetAgentIds } from "../preset_agents";
import { PresetAgent } from "../types";
import { config as relevance_config } from "./relevance_config";
import { HarvestRuntime } from "./harvest_runtime";

export const backgroundCoderAgent = new PresetAgent({
  id: PresetAgentIds.backgroundCoder,
  Run: HarvestRuntime,
  relevance_config,
  relevance_only: true,
  display_credits_cost_per_message: 2000,
  display_in_chat: true,
});
```

#### 3.2 `apps/nodeapi/src/agent/preset_agents/background_coder/harvest_runtime.ts`

```typescript
import { spawn } from "child_process";
import type { ConversationManager } from "~/agent/conversation_manager";
import { GetUserProjectKey } from "~/helpers/account_helpers";
import { logger } from "~/utilities/log";

export const HarvestRuntime = async (convo: ConversationManager) => {
  const projectId = convo.a.project as string;
  const conversationId = convo.conversation_id;

  // Retrieve credentials
  const githubToken = await GetUserProjectKey(projectId, "github_access_token", false);
  const claudeToken = await GetUserProjectKey(projectId, "anthropic", false);
  const geminiKey = await GetUserProjectKey(projectId, "google", false);

  if (!githubToken) {
    throw new Error("GitHub access token required. Add it to project secrets.");
  }
  if (!claudeToken) {
    throw new Error("Anthropic API key required. Add it to project secrets.");
  }

  // Get user message
  const userMessages = convo.relevance_conversation
    .filter((msg) => msg.role === "user")
    .map((msg) => msg.content);
  const latestPrompt = userMessages[userMessages.length - 1];

  // Spawn harvest-client subprocess
  const harvestProcess = spawn("python", [
    "-m", "harvest_client",
    "--session-id", conversationId,
    "--prompt", latestPrompt,
    "--repo-owner", "RelevanceAI",  // TODO: Make configurable
    "--repo-name", "relevance-chat-app",  // TODO: Make configurable
    "--github-token", githubToken,
    "--claude-token", claudeToken,
    ...(geminiKey ? ["--gemini-key", geminiKey] : []),
  ]);

  // Stream stdout to ConversationManager (shows in right pane)
  for await (const chunk of harvestProcess.stdout) {
    yield {
      stdout: chunk.toString(),
    };
  }

  // Check for errors
  const stderr = [];
  for await (const chunk of harvestProcess.stderr) {
    stderr.push(chunk.toString());
  }

  if (stderr.length > 0) {
    logger.error("Harvest process error:", stderr.join(""));
  }

  return { credits_used: 0 };
};
```

#### 3.3 `apps/nodeapi/src/agent/preset_agents/background_coder/relevance_config.ts`

```typescript
import type { AgentConfig } from "~/codegeneration/generated_api_types";
import { MAX_AGENT_AUTONOMY_LIMIT } from "~/agent/constants";
import { ANTHROPIC_MAX_OUTPUT_TOKENS } from "~/llm/models/anthropic_constants";
import { PresetAgentIds } from "../preset_agents";
import { GetPresetAgentId } from "../utils";

const AGENT_ID = GetPresetAgentId(PresetAgentIds.backgroundCoder);

export const config: Omit<AgentConfig, "_id" | "project"> = {
  type: "chat-orchestrator",
  name: "Background Coder",
  description: "A powerful autonomous coding agent powered by Claude Code CLI with persistent memory and sophisticated git workflows.",
  prompt_description: "An autonomous coding agent that can work on repositories in the background, fix tests, create PRs, and respond to triggers from Slack, GitHub, or webhooks.",
  emoji: "https://cdn.jsdelivr.net/gh/RelevanceAI/content-cdn@latest/studio/harvest-logo.png",
  agent_id: AGENT_ID,
  system_prompt: "", // Claude Code CLI manages its own prompts
  model: "anthropic-claude-sonnet-4-5",
  conversation_compression_enabled: true,
  model_options: {
    max_output_tokens: ANTHROPIC_MAX_OUTPUT_TOKENS,
  },
  max_job_duration: "hours",
  autonomy_limit: MAX_AGENT_AUTONOMY_LIMIT,
  runtime: {
    engine: "preset",
    preset: {
      preset_agent_id: PresetAgentIds.backgroundCoder,
    },
  },
};
```

#### 3.4 `apps/nodeapi/src/agent/preset_agents/background_coder/cancel.ts`

```typescript
/**
 * Cancel endpoint for Background Coder agent
 */
import type { Request, Response } from "express";
import { logger } from "~/utilities/log";

const MODAL_ENDPOINT = process.env.MODAL_HARVEST_ENDPOINT || "https://your-modal-endpoint.modal.run";

export async function cancelBackgroundCoder(req: Request, res: Response) {
  const { conversation_id } = req.params;

  if (!conversation_id) {
    return res.status(400).json({ error: "conversation_id required" });
  }

  try {
    // Call Modal cancel endpoint (server-to-server, no CORS)
    const response = await fetch(`${MODAL_ENDPOINT}/cancel/${conversation_id}`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
    });

    const result = await response.json();

    if (result.success) {
      logger.info(`Cancelled Background Coder session: ${conversation_id}`);
      return res.json({ success: true });
    } else {
      logger.warn(`Failed to cancel session ${conversation_id}: ${result.error}`);
      return res.status(404).json({ success: false, error: result.error });
    }
  } catch (error) {
    logger.error("Error cancelling Background Coder session:", error);
    return res.status(500).json({
      success: false,
      error: "Internal server error"
    });
  }
}
```

#### 3.5 `apps/nodeapi/src/agent/preset_agents/preset_agents.ts`

**Add to PresetAgentIds enum:**
```typescript
export enum PresetAgentIds {
  // ... existing agents
  backgroundCoder = "background-coder",
}
```

#### 3.6 `apps/nodeapi/src/agent/preset_agents/register_preset_agents.ts`

**Import and register:**
```typescript
import { backgroundCoderAgent } from "./background_coder/agent";

// ... existing registrations
backgroundCoderAgent.register();
```

#### 3.7 `apps/nodeapi/src/routes/agent/HarvestCancel.ts`

**New route for cancellation:**
```typescript
import type { HttpRoutingPattern } from "~/types";
import { cancelBackgroundCoder } from "~/agent/preset_agents/background_coder/cancel";

export const HarvestCancelRoute: HttpRoutingPattern = {
  url: "/api/agents/harvest/cancel/:conversation_id",
  method: "POST",
  handler: cancelBackgroundCoder,
  validation_schemas: {
    // No body schema needed
  },
};
```

### Phase 4: Testing & Validation

**Goal:** Verify end-to-end functionality

#### 4.1 Unit Tests

**File:** `packages/modal-executor/tests/test_pty_wrapper.py`

```python
"""Tests for PTY wrapper"""
import pytest
from modal_executor.pty_wrapper import PTYWrapper

@pytest.mark.asyncio
async def test_pty_read_write():
    """Test basic PTY read/write"""
    # Create simple echo process
    master, slave = pty.openpty()
    proc = await asyncio.create_subprocess_exec(
        "cat",
        stdin=slave,
        stdout=slave,
        stderr=slave,
    )

    wrapper = PTYWrapper(master, slave, proc)

    # Write and read
    await wrapper.write("hello\n")
    result = await wrapper.read(timeout=1)

    assert "hello" in result

    wrapper.close()
```

#### 4.2 Integration Tests

**File:** `apps/nodeapi/src/tests/integration/preset_agents/background_coder.test.ts`

```typescript
describe("BackgroundCoderPresetAgent", () => {
  it("should stream output to toolviewer", async () => {
    const agent = backgroundCoderAgent;
    const conversationManager = createTestConversationManager({
      message: "Say hello",
      project_id: "test-project",
    });

    const chunks = [];
    for await (const chunk of agent.Run(conversationManager)) {
      chunks.push(chunk);
    }

    expect(chunks.length).toBeGreaterThan(0);
    expect(chunks[0]).toHaveProperty("stdout");
  });

  it("should handle cancellation", async () => {
    // Start long-running task
    const conversationId = "test-convo-123";

    // Send cancel request
    const response = await fetch(`/api/agents/harvest/cancel/${conversationId}`, {
      method: "POST",
    });

    expect(response.status).toBe(200);
    const result = await response.json();
    expect(result.success).toBe(true);
  });
});
```

#### 4.3 Manual Testing Checklist

- [ ] Agent appears in Chat UI dropdown
- [ ] User can send message, see streaming output in right pane
- [ ] Second message queues while first is processing
- [ ] Cancel button stops execution mid-stream
- [ ] Session resumes after 5-minute idle timeout
- [ ] Memory limit (6GB) prevents runaway processes
- [ ] Multiple concurrent conversations work (agentic swarms)
- [ ] Slack trigger integration works
- [ ] GitHub webhook trigger works (via Custom Webhooks)

## Success Criteria

1. **Functionality:**
   - ✅ User can send prompts via Chat UI
   - ✅ Output streams to right pane (toolviewer) in real-time
   - ✅ Multiple messages queue properly
   - ✅ Cancellation works mid-execution
   - ✅ Context preserved across prompts in same session

2. **Performance:**
   - ✅ Cold start <5 seconds (Modal memory snapshots)
   - ✅ Warm response <500ms to first chunk
   - ✅ 10+ concurrent sessions supported

3. **Reliability:**
   - ✅ Memory limit prevents runaway usage
   - ✅ Idle timeout terminates containers (cost savings)
   - ✅ SQLite persistence survives container restarts
   - ✅ 95%+ success rate for prompt completion

4. **Cost:**
   - ✅ <$0.05 per user hour (with 5-min idle timeout)
   - ✅ Modal auto-scaling handles load spikes

## Risks & Mitigations

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| **Claude memory leaks** | High | High | 6GB container limit, 12-hour session timeout, 5-min idle timeout, memory monitoring |
| **PTY parsing fragility** | Medium | Medium | Stop hook provides clear message boundary |
| **Modal cold starts** | Low | Medium | Memory snapshots reduce to <3s, acceptable UX |
| **Stop hook doesn't fire** | High | Low | Add timeout fallback (if no marker after 30min, assume done) |
| **Concurrent queue conflicts** | Medium | Low | Use asyncio.Queue (thread-safe) |
| **CORS issues** | Low | Low | Route through Relevance API (server-to-server) |
| **Credential leakage** | High | Low | Modal secrets, no repr on dataclasses, audit logs |

## Rollout Plan

### Week 1: Harvest Implementation
- Day 1-2: PTY infrastructure (Phase 1)
- Day 3-4: harvest-client package (Phase 2)
- Day 5: Testing and debugging

### Week 2: Relevance Integration
- Day 1-2: BackgroundCoderPresetAgent (Phase 3)
- Day 3: Cancel endpoint and routes
- Day 4-5: Integration testing

### Week 3: Production Rollout
- Day 1-2: Deploy to staging
- Day 3: Internal dogfooding
- Day 4: Fix issues, optimize
- Day 5: Production release (feature flag)

### Week 4: Monitoring & Iteration
- Monitor memory usage, cold starts, success rates
- Gather user feedback
- Iterate on idle timeout, memory limits

## Open Questions

1. **Repo configuration:** Should repo_owner/repo_name be configurable per prompt, or per agent configuration?
2. **Cost limits:** Should we enforce per-user or per-org session limits?
3. **Extended sessions:** Should we support tasks >12 hours with checkpointing? Current 12-hour limit supports overnight work (core use case).

## Related Work

- [PR #10748: Harvest Integration Plan](https://github.com/RelevanceAI/relevance-api-node/pull/10748)
- [Ramp Inspect Architecture](https://builders.ramp.com/post/why-we-built-our-background-agent)
- [Claude Code Hooks Documentation](https://code.claude.com/docs/en/hooks)
- [Modal Cold Start Performance](https://modal.com/docs/guide/cold-start)

## Next Steps

1. Review this plan with team
2. Get approval for approach
3. Create implementation branch
4. Begin Phase 1 (PTY infrastructure)

---

**Plan Status:** ✅ Ready for review
**Estimated Effort:** 3 weeks (1 dev)
**Dependencies:** Modal account, Claude Code CLI team subscription
**Risk Level:** Medium (new PTY approach, but well-researched)
